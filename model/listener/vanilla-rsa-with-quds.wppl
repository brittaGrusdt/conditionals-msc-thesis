////////////  SET PARAMETERS  /////////////////
var alpha = 5
var thresholds = {t: 0.9, f: 0.05, likely: 0.7, theta: 0.9, theta_likely: 0.6}
var utteranceDict = {"null": ["null"],
                     'simple': ["A", "C", "-A", "-C"],
                     'probs' : ["likely A", "likely C", "likely -A", "likely -C"],
                     'conj' : ["A and C", "C but -A", "A but -C", "neither A nor C"],
                     'if' : ["If A, C", "If A, -C", "If -A, C", "If -A, -C",
                             "If C, A", "If C, -A", "If -C, A", "If -C, -A"]}
var utterances = reduce(function(utts,acc){acc.concat(utts)},[],
                        Object.values(utteranceDict))

var independentNets = ["A ind. C"]
var dependentAC = ["A implies C", "A implies -C", "-A implies C", "-A implies -C"]
var dependentCA = ["C implies A", "C implies -A", "-C implies A", "-C implies -A"]
var dependentNets = dependentAC.concat(dependentCA)
var causalNets = independentNets.concat(dependentNets)

var params = {'none_p_ind': 1/3,
             'lawn-nn_p_ind': 1/3,
             'pizza_p_ind': 1,
             'douven1_p_ind': 0.9,
             'wason-abstract_p_ind': 1/8}

var roundTo3 = function(x){
  return Math.round(x*1000)/1000
}
// marginal probabilities
var pa = function(x){return x[0]+x[2]}
var pc = function(x){return x[0]+x[1]}
var pna = function(x){return x[1]+x[3]}
var pnc = function(x){return x[2]+x[3]}
// conditional probabilities
var pAgivenC = function(x){return x[0]/pc(x)}
var pAgivenNC = function(x){return x[2]/pnc(x)}
var pNAgivenC = function(x){return x[1]/pc(x)}
var pNAgivenNC = function(x){return x[3]/pnc(x)}
var pCgivenA = function(x){return x[0]/pa(x)}
var pCgivenNA = function(x){return x[1]/pna(x)}

///////////// PRIORS /////////////
var tablesPrior = mem(function(){
  return Infer({method:'rejection', samples:5000, model:function(){
    var x1 = sample(Uniform({a:0,b:1}));
    var x2 = sample(Uniform({a:0,b:1}));
    var x3 = sample(Uniform({a:0,b:1}));
    condition(x1+x2+x3<1)
    var x4 = 1-(roundTo3(x1+x2+x3))
    return [x1,x2,x3,x4]
}})})

var tables = tablesPrior().support()
display('nb tables: ' + tables.length)

var span = 0.03
var logLikelihood = cache(function(table, cn){
  var p = cn=="A implies C" ? pCgivenA(table) :
  cn=='A implies -C' ? 1-pCgivenA(table)  :
  cn=='-A implies C' ? pCgivenNA(table) :
  cn=='-A implies -C' ? 1-pCgivenNA(table) :
  cn=="C implies A"  ? pAgivenC(table):
  cn=="C implies -A" ? 1-pAgivenC(table) :
  cn=="-C implies A" ? pAgivenNC(table) :
  cn=="-C implies -A" ? 1-pAgivenNC(table) :
  cn=="A ind. C" ? ((pCgivenA(table) >= (pCgivenNA(table) - span) &&
                    pCgivenA(table) <= (pCgivenNA(table) + span))
                    &&
                    (pAgivenC(table) >= (pAgivenNC(table) - span) &&
                    pAgivenC(table) <= (pAgivenNC(table) + span)) ? 0.99 : 0.01) :

  error('unknown cn in likelihood: ' + cn)

  var logL =  Beta({a:10, b:1}).score(p)
  return logL
})

var getCNpriors = function(p_ind){
  return [p_ind].concat(repeat(dependentNets.length,
                               function(){(1-p_ind)/dependentNets.length}))
}
var networkPrior = function(bias) {
  return categorical({vs: causalNets, ps: getCNpriors(params[bias+'_p_ind'])})
}

var bayesNetPrior = cache(function(bias){
  return Infer({method:'enumerate', model:function(){
    var table = uniformDraw(tables)
    var cn = networkPrior(bias)
    factor(logLikelihood(table, cn))
    if(bias=='lawn-nn'){
      if(pCgivenNA(table)<=1-thresholds.likely){factor(-Math.log(thresholds.f))}
    }
    else if(bias=='douven1'){
      if(pc(table)>=thresholds.likely){factor(-Math.log(thresholds.f))}
    }
    return {"cn": cn, "table": table}
  }})
})

var qudPrior = Infer({method:'enumerate', model: function(){
  return categorical({vs: ['bn', 'table', 'cn'], ps: [1,1, 1]})}
})

///////////// MODEL /////////////
var utteranceProbs = cache(function(utterance, table){
  var p = utterance == "A" ? pa(table) :
  utterance == "C" ? pc(table) :
  utterance == "If A, C" ? table[0]/pa(table) :
  utterance == "If C, A" ? table[0]/pc(table) :
  utterance == "-A" ? pna(table) :
  utterance == "-C" ? pnc(table) :
  utterance == "If A, -C" ? table[2]/pa(table) :
  utterance == "If -A, C" ? table[1] / pna(table) :
  utterance == "If -A, -C" ? table[3] / pna(table) :
  utterance == "If C, -A" ? table[1] / pc(table) :
  utterance == "If -C, A" ? table[2] / pnc(table):
  utterance == "If -C, -A" ? table[3] / pnc(table) :
  utterance == "likely A" ? table[0] + table[2] :
  utterance == "likely C" ? table[0] + table[1] :
  utterance == "likely -A" ? table[1] + table[3] :
  utterance == "likely -C" ? table[2] + table[3] :
  utterance == "A and C" ? table[0] :
  utterance == "neither A nor C" ? table[3] :
  utterance == "A but -C" ? table[2] :
  utterance == "C but -A" ? table[1] :
  utterance == "null" ?
    true : error("unknown utterance " + utterance)
  return p
})

var meaning = cache(function(utterance, table, cn){
 var p = utteranceProbs(utterance, table)
 var p_holds = utterance.includes('likely') ?
     (p >= thresholds.theta_likely) : p >= thresholds.theta
 return p_holds
})

var literalListener = cache(function(utterance, qud, bias){
  Infer({method:'enumerate',model: function(){
    var bn = sample(bayesNetPrior(bias))
    condition(meaning(utterance, bn.table))
    if(qud=='cn'){return bn.cn}
    else if(qud == 'table'){return bn.table}
    else{return bn}
  }})
}, 10000)

var costs = function(utterance){
  var cost = utterance == "null" ? 20 :
  utteranceDict['if'].includes(utterance) ?  0.75:
  utteranceDict['conj'].includes(utterance) ? 0.5 :
  utteranceDict['probs'].includes(utterance) ? 0.25 :
  utteranceDict['simple'].includes(utterance) ? 0 :

  error('costs: unknown utterance ' + utterance)
  return cost
}

var speaker = cache(function(bn, bias, qud){
  return Infer({method:'enumerate', model: function(){
    var utterance = uniformDraw(utterances)
    var LL = literalListener(utterance, qud, bias)
    var utility = qud=='bn' ? LL.score(bn) : qud=='cn' ? LL.score(bn.cn) :
    qud=='table' ? LL.score(bn.table) : error('unknown speaker qud: ' + qud)
//     print(utterance + utility)
    factor(alpha * (utility - costs(utterance)))
    return utterance
  }
 })
}, 10000)

var listener = function(utterance, bias, speakerIntent){
  return Infer({method:'enumerate', model:function(){
                  var bn = sample(bayesNetPrior(bias))
                  var qud = speakerIntent ? speakerIntent: sample(qudPrior)
                  observe(speaker(bn, bias, qud),utterance)
                  return {qud: qud, bn: bn}
                }})
}

//-----MAKE PLOTS-----//
var speakerExpectation = function(n, qud, bias, utterance){
  var bnsFromPrior = repeat(n, function(){return sample(bayesNetPrior(bias))})
  var likelihoods = map(function(bn){
    var speakerBeliefs = speaker(bn, bias, qud)
    var likelihood = Math.exp(speakerBeliefs.score(utterance))
    return likelihood
  }, bnsFromPrior)
  return likelihoods
}

// ---For R-scripts---
var bias = myDF["bias"][0]
var utterance = myDF["utterance"][0]
display('bias: ' + bias + ' utterance: ' + utterance)
// 1. joint distributions (run-across-biases.r)
// var PL = listener(utterance, bias)
// PL


// 2. speaker suprisal (speaker-expectations.r)
var qud = myDF["qud"][0]
display(qud)
var se = speakerExpectation(1000,qud, bias, utterance)
se

//3. conditional distributions
// var cn = myDF["cn"][0]
// display(cn)

// var PL = listener(utterance, bias)
// var conditionalDistr = Infer(model:function(){
//     var state = sample(PL)
//     condition(state['bn'].cn== cn)
//     return state
//   })
// conditionalDistr

