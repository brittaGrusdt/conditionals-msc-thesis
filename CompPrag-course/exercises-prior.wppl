////////////  SET PARAMETERS  /////////////////
globalStore.alpha = 5
globalStore.thetaCP = 0.05
var thresholds = {t: 0.9, f: 0.05, likely: 0.7, theta: 0.9, theta_likely: 0.5}

var independentNets = ["A ind. C"]
var dependentAC = ["A implies C", "A implies -C", "-A implies C", "-A implies -C"]
var dependentCA = ["C implies A", "C implies -A", "-C implies A", "-C implies -A"]
var dependentNets = dependentAC.concat(dependentCA)
var causalNets = independentNets.concat(dependentNets)

var prob_ac_ind = {"none": 1/2,
                  "lawn": 1/2,
                  "lawn-cond": 1/2,
                  "pizza" : 1,
                  "douven1": 0.98,
                  "BC-impossible-cons": 1
                  }

////////////  HELPERS  /////////////////
var roundToN = function(x, n){
  var m = Math.pow(10,n)
  return Math.round(x*m)/m
}
// marginal probabilities
var pa = function(x){return x[0]+x[2]}
var pc = function(x){return x[0]+x[1]}
var pna = function(x){return x[1]+x[3]}
var pnc = function(x){return x[2]+x[3]}
// conditional probabilities
var pAgivenC = function(x){return x[0]/pc(x)}
var pAgivenNC = function(x){return x[2]/pnc(x)}
var pNAgivenC = function(x){return x[1]/pc(x)}
var pNAgivenNC = function(x){return x[3]/pnc(x)}
var pCgivenA = function(x){return x[0]/pa(x)}
var pCgivenNA = function(x){return x[1]/pna(x)}


////////////  PRIORS  /////////////////
var tablesPrior = mem(function(){
  return Infer({method:'forward', samples:1000, model:function(){
    var alpha = Vector(repeat(4, constF(0.25)));
    var vec = dirichlet({alpha})
    var table = Object.values(vec.data)
    var table = map2(roundToN, table, [2,2,2,2])
    return table
}})})

var tables = tablesPrior().support()
display('nb tables: ' + tables.length)


var logLikelihood = cache(function(table, cn){
  var p = cn=="A implies C" ? pCgivenA(table) :
  cn=='A implies -C' ? 1-pCgivenA(table)  :
  cn=='-A implies C' ? pCgivenNA(table) :
  cn=='-A implies -C' ? 1-pCgivenNA(table) :
  cn=="C implies A"  ? pAgivenC(table):
  cn=="C implies -A" ? 1-pAgivenC(table) :
  cn=="-C implies A" ? pAgivenNC(table) :
  cn=="-C implies -A" ? 1-pAgivenNC(table) :
  cn=="A ind. C" ?
      (Math.abs(pCgivenA(table) - pCgivenNA(table)) <= 0.03 &&
       Math.abs(pAgivenC(table) - pAgivenNC(table)) <= 0.03 ?
       0.99 : 0.01) :

  error('unknown cn in likelihood: ' + cn)

  var logL = Beta({a:10, b:1}).score(p)

  return logL
})

var getCNpriors = function(p_ind){
  return [p_ind].concat(repeat(dependentNets.length,
                               function(){(1-p_ind)/dependentNets.length}))
}
var networkPrior = function(bias) {
  return categorical({vs: causalNets, ps: getCNpriors(prob_ac_ind[bias])})
}

var bias = "none"
var bayesNetPrior = cache(function(bias, conditioned_on){
  return Infer({method:'enumerate', model:function(){
    var table = uniformDraw(tables)
    var cn = networkPrior(bias)
    factor(logLikelihood(table, cn))
    // condition(cn==conditioned_on) // just for exercise
    return {cn, table}
  }})
})

viz(repeat(1000, function(){networkPrior(bias)}))

viz(marginalize(bayesNetPrior(bias), "cn"))



// EXERCISES
// Uncomment the line starting with condition in the bayesNetPrior
// and sample some bayes nets from the prior to see some of the final world states
// conditioned on various causal networks (see above for their definition)

var cn = "A implies C"
// var cn = "A ind. C"
var bn = sample(bayesNetPrior(bias, cn))

print('cn: '  + bn["cn"])
print('     A  ' + '     -A ')
print('C  | ' + bn["table"][0] + " | " + bn["table"][1])
print('-C | ' + bn["table"][2] + " | " + bn["table"][3])

var p1 = roundToN(pCgivenA(bn["table"]), 2)
var p2 = roundToN(pCgivenNA(bn["table"]),2)
var p3 = roundToN(pAgivenC(bn["table"]), 2)
var p4 = roundToN(pAgivenNC(bn["table"]), 2)

print('')

print('P(C|A): ' + p1)
print('P(C|-A): ' + p2)
print('P(C):' + pc(bn["table"]))

print('')

print('P(A|C)' + p3)
print('P(A|-C)' + p4)
print('P(A):' + pa(bn["table"]))
